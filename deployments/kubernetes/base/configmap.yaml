apiVersion: v1
kind: ConfigMap
metadata:
  name: nebulaio-config
  namespace: nebulaio
  labels:
    app.kubernetes.io/name: nebulaio
    app.kubernetes.io/component: config
data:
  config.yaml: |
    # NebulaIO Configuration
    node_name: "${HOSTNAME}"
    data_dir: /data

    s3_port: 9000
    admin_port: 9001
    console_port: 9002

    # TLS Configuration (Secure by Default)
    # NebulaIO is secure by default with TLS enabled and auto-generated certificates
    tls:
      enabled: true              # TLS enabled by default
      auto_generate: true        # Auto-generate self-signed certificates
      cert_dir: /data/certs      # Certificate storage directory
      min_version: "1.2"         # Minimum TLS 1.2
      require_client_cert: false # Enable for mTLS
      organization: NebulaIO
      validity_days: 365
      # For custom certificates, uncomment and set:
      # cert_file: /etc/nebulaio/certs/server.crt
      # key_file: /etc/nebulaio/certs/server.key
      # ca_file: /etc/nebulaio/certs/ca.crt

    cluster:
      bootstrap: ${NEBULAIO_CLUSTER_BOOTSTRAP:-false}
      shard_id: 1
      replica_id: ${NEBULAIO_REPLICA_ID:-1}  # Must be unique per node (uint64)
      raft_port: 9003
      wal_dir: /data/wal
      snapshot_count: 10000
      compaction_overhead: 5000
      gossip_port: 9004
      node_role: storage
      cluster_name: nebulaio-k8s
      # Dragonboat RTT-based timeouts
      rtt_millisecond: 200
      election_rtt: 10
      heartbeat_rtt: 1

    # Storage configuration
    storage:
      backend: fs  # fs | erasure | volume
      path: /data/objects
      default_storage_class: STANDARD

      # Default redundancy configuration (for erasure backend)
      # Applies to all buckets unless overridden
      # default_redundancy:
      #   enabled: true
      #   data_shards: 10           # Reed-Solomon data shards
      #   parity_shards: 4          # Reed-Solomon parity shards
      #   placement_policy: spread  # spread | local | rack-aware | zone-aware
      #   replication_factor: 1     # Cross-placement group DR copies

      # Placement groups for distributed storage
      # Erasure coding and tiering happen within a placement group
      # Cross-placement group replication for DR uses full object copies
      # placement_groups:
      #   local_group_id: pg-dc1
      #   min_nodes_for_erasure: 3
      #   replication_targets:
      #     - pg-dc2
      #   groups:
      #     - id: pg-dc1
      #       name: "Datacenter 1"
      #       datacenter: dc1
      #       region: us-east-1
      #       min_nodes: 3
      #       max_nodes: 10

      # Per-tier storage backends (enables mixed backend types)
      # tiering:
      #   enabled: true
      #   tiers:
      #     hot:
      #       backend: erasure       # Use erasure for hot tier
      #       data_dir: /data/hot
      #       erasure_config:
      #         data_shards: 10
      #         parity_shards: 4
      #       priority: 1
      #       capacity_threshold: 0.85
      #     warm:
      #       backend: volume        # Use volume for warm tier
      #       data_dir: /data/warm
      #       priority: 2
      #     cold:
      #       backend: fs            # Use filesystem for cold tier
      #       data_dir: /data/cold
      #       priority: 3
      #   policies:
      #     - name: age-based-cold
      #       enabled: true
      #       source_tier: hot
      #       destination_tier: cold
      #       condition:
      #         type: age
      #         age_days: 30

      # Volume storage (when backend: volume)
      # High-performance block-based storage with pre-allocated volume files
      # volume:
      #   max_volume_size: 34359738368  # 32GB per volume file
      #   auto_create: true             # Auto-create new volumes when needed

      # Compression (uncomment to enable)
      # compression: zstd  # none | zstd | lz4 | gzip
      # compression_level: 3

      # Erasure coding (when backend: erasure)
      # erasure:
      #   data_shards: 10
      #   parity_shards: 4

    # Identity providers (configure via secrets)
    # identity:
    #   ldap:
    #     enabled: false
    #     server_url: ldap://ldap.example.com:389
    #     bind_dn: cn=admin,dc=example,dc=com
    #     bind_password: ${LDAP_BIND_PASSWORD}
    #     user_search_base: ou=users,dc=example,dc=com
    #     user_search_filter: "(uid={username})"
    #     group_search_base: ou=groups,dc=example,dc=com
    #     tls: true
    #
    #   oidc:
    #     enabled: false
    #     issuer_url: https://auth.example.com
    #     client_id: nebulaio
    #     client_secret: ${OIDC_CLIENT_SECRET}
    #     redirect_url: https://console.example.com/callback
    #     scopes: ["openid", "profile", "email"]

    # KMS Integration (configure via secrets)
    # kms:
    #   provider: vault  # local | vault | aws | gcp | azure
    #   vault:
    #     address: https://vault.example.com:8200
    #     token: ${VAULT_TOKEN}
    #     mount: transit
    #     key_name: nebulaio-master

    # Replication (for multi-site deployments)
    # replication:
    #   enabled: false
    #   sites:
    #     - name: site2
    #       endpoint: https://site2.example.com:9000
    #       access_key: ${SITE2_ACCESS_KEY}
    #       secret_key: ${SITE2_SECRET_KEY}

    # Event Notifications
    # events:
    #   enabled: false
    #   targets:
    #     - name: kafka
    #       type: kafka
    #       brokers: ["kafka:9092"]
    #       topic: s3-events

    # Storage Tiering
    # tiering:
    #   enabled: false
    #   cache:
    #     enabled: true
    #     max_size: 10737418240  # 10GB
    #   cold_storage:
    #     - name: glacier
    #       type: s3
    #       endpoint: https://s3.amazonaws.com
    #       bucket: my-cold-tier

    # DRAM Cache
    # High-performance in-memory cache for AI/ML workloads
    # cache:
    #   enabled: false
    #   max_size: 8589934592       # 8GB maximum cache size
    #   shard_count: 256           # Lock sharding for concurrency
    #   entry_max_size: 268435456  # 256MB max single entry
    #   ttl: 3600                  # Default TTL in seconds
    #   eviction_policy: arc       # lru | lfu | arc
    #   prefetch_enabled: true     # ML-optimized prefetching
    #   prefetch_threshold: 2      # Sequential reads before prefetch
    #   prefetch_ahead: 4          # Chunks to prefetch
    #   zero_copy_enabled: true    # Zero-copy reads
    #   distributed_mode: false    # Distributed cache across nodes

    # Data Firewall
    # QoS, rate limiting, bandwidth throttling, access control
    # firewall:
    #   enabled: false
    #   default_policy: allow      # allow | deny
    #   audit_enabled: true
    #   rate_limiting:
    #     enabled: true
    #     requests_per_second: 1000
    #     burst_size: 100
    #     per_user: true
    #     per_ip: true
    #     per_bucket: false
    #     # Object creation rate limiting (Hash DoS protection)
    #     # Protects against attacks that target object key distribution
    #     # Applies to: PutObject, CopyObject, CompleteMultipartUpload, UploadPart
    #     object_creation_limit: 1000      # RPS for object creation operations
    #     object_creation_burst_size: 2000 # Burst size for object creation
    #   bandwidth:
    #     enabled: true
    #     max_bytes_per_second: 1073741824      # 1GB/s global
    #     max_bytes_per_second_per_user: 104857600  # 100MB/s per user
    #     max_bytes_per_second_per_bucket: 524288000  # 500MB/s per bucket
    #   connections:
    #     enabled: true
    #     max_connections: 10000
    #     max_connections_per_ip: 100
    #     max_connections_per_user: 500
    #   ip_allowlist: []
    #   ip_blocklist: []
    #   rules: []

    # S3 Select
    # SQL queries on CSV/JSON/Parquet without full download
    # s3_select:
    #   enabled: true
    #   max_record_size: 1048576   # 1MB
    #   max_results_size: 268435456  # 256MB
    #   timeout: 300               # Query timeout seconds
    #   worker_pool_size: 10

    # =========================================================================
    # AI/ML Features (2025)
    # =========================================================================

    # S3 Object Lambda with WASM Runtime
    # Serverless object transformations using WebAssembly
    # object_lambda:
    #   enabled: false
    #   wasm:
    #     enabled: true
    #     max_memory_mb: 256           # Maximum memory for WASM modules
    #     max_execution_time: 30s      # Maximum execution time
    #     max_input_size: 104857600    # 100MB max input
    #     max_output_size: 104857600   # 100MB max output
    #     streaming_threshold: 10485760 # 10MB - objects larger use streaming
    #     module_path: /data/wasm       # WASM module directory
    #     cache_enabled: true           # Cache compiled modules
    #     cache_max_modules: 100        # Maximum cached modules

    # S3 Express One Zone
    # Ultra-low latency storage with atomic append support
    # s3_express:
    #   enabled: false
    #   default_zone: use1-az1
    #   session_duration: 300
    #   max_append_size: 5368709120   # 5GB
    #   enable_atomic_append: true
    #   zones:
    #     - id: use1-az1
    #       name: US East 1 AZ1
    #       region: us-east-1
    #       storage_class: EXPRESS_ONEZONE

    # Apache Iceberg Integration
    # Native table format for data lakehouse workloads
    # iceberg:
    #   enabled: false
    #   catalog_type: rest           # rest | hive | glue
    #   warehouse: s3://warehouse/
    #   catalog_name: nebulaio
    #   enable_acid: true
    #   snapshot_retention: 5
    #   metadata_refresh_interval: 60
    #   rest_catalog:
    #     port: 9006
    #     prefix: /iceberg

    # MCP Server (Model Context Protocol)
    # AI agent integration for Claude, ChatGPT, and other LLMs
    # mcp:
    #   enabled: false
    #   port: 9005
    #   enable_tools: true
    #   enable_resources: true
    #   enable_prompts: true
    #   max_resource_size: 10485760  # 10MB
    #   allowed_buckets: []          # Empty = all buckets
    #   auth_required: true
    #   rate_limit: 100              # Requests per minute

    # GPUDirect Storage
    # Zero-copy GPU-to-storage transfers for AI/ML workloads
    # gpudirect:
    #   enabled: false
    #   device_ids: []               # Empty = auto-detect
    #   buffer_pool_size: 1073741824 # 1GB
    #   max_transfer_size: 268435456 # 256MB
    #   enable_async: true
    #   enable_p2p: true             # Peer-to-peer GPU transfers
    #   queue_depth: 64

    # BlueField DPU Offload
    # SmartNIC acceleration for crypto, compression, and RDMA
    # dpu:
    #   enabled: false
    #   device_name: mlx5_0
    #   enable_crypto: true          # AES-GCM offload
    #   enable_compression: true     # Deflate/LZ4 offload
    #   enable_rdma: true            # RDMA acceleration
    #   crypto_queue_size: 256
    #   compression_queue_size: 256

    # S3 over RDMA
    # Ultra-low latency object access via InfiniBand/RoCE
    # rdma:
    #   enabled: false
    #   port: 9100
    #   device_name: mlx5_0
    #   ib_port: 1
    #   gid_index: 0
    #   enable_zero_copy: true
    #   max_send_wr: 128
    #   max_recv_wr: 128
    #   max_sge: 4
    #   cq_size: 256

    # NVIDIA NIM Integration
    # Run AI inference on stored objects
    # nim:
    #   enabled: false
    #   api_key: ${NIM_API_KEY}
    #   endpoint: https://integrate.api.nvidia.com/v1
    #   default_model: meta/llama-3.1-8b-instruct
    #   enable_streaming: true
    #   timeout: 300
    #   max_retries: 3
    #   cache_responses: true
    #   cache_ttl: 3600

    # Batch Replication
    # Bulk data migration and disaster recovery
    # batch_replication:
    #   enabled: false
    #   max_concurrent_jobs: 5
    #   default_concurrency: 10
    #   max_retries: 3
    #   retry_delay: 5s
    #   history_limit: 100
    #   checkpoint_interval: 1000

    # Enhanced Audit Logging
    # Compliance-ready audit trails with cryptographic integrity
    # audit:
    #   enabled: true
    #   compliance_mode: none      # none | soc2 | pci | hipaa | gdpr | fedramp
    #   file_path: /data/audit/audit.log
    #   retention_days: 90
    #   buffer_size: 10000
    #   integrity_enabled: true    # Cryptographic integrity chain
    #   mask_sensitive_data: true
    #   sensitive_fields:
    #     - password
    #     - secret
    #     - token
    #     - credential
    #     - key
    #   rotation:
    #     enabled: true
    #     max_size_mb: 100
    #     max_age_days: 7
    #     max_backups: 10
    #     compress: true
    #   webhook:
    #     enabled: false
    #     url: ""
    #     batch_size: 100
    #     flush_interval: 5s
    #     retry_count: 3

    log_level: info
    log_format: json

    metrics:
      enabled: true
      port: 9090
      path: /metrics
